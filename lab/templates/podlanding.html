{% extends "base_cisco.html" %}
{% from "macros.html" import file, warn, info, cmd_blk_end, cmd_blk_start, term_end, topxterm, term_start, end_of_page,top_instance %}
{% block content %}
<div class="section_header">
    <div class="title">Introduction</div>
    <div class="title_section">Why Containers?</div>
</div>
<h1>
    Understanding Containers
</h1>
<p>
    You would have to live under a rock today to not have heard about containers and Docker. They
    have taken over the techie world by storm. Originally known in Linux circles and mostly
    focused around application programing, containers are a new architectural method of
    collecting what is needed to provide a service. Instead of having long installation
    instructions with information of packages that are needed to get a service operational,
    containers can be written to contain all that is needed for the service to run.
</p>
<div class="row">
    <div class="col-md-6 col-sm-12">
        <p>
            Containers differ from normal Virtual Machines (VM's) in the fact that containers
            running on the same host share the underlying kernel amongst them. This variation
            means that the operating system doesn't need to be "reproduced". This provides two
            separate important things: you can start containers very quickly to
            provide the service, and they can be made to be extremely small in
            size.
        </p>
        <p>
            Yet, what are these services we keep talking about? Since the days of
            application development on mainframe computers, developers
            have been working to "compartmentalize" the applications they
            developed into smaller, more manageable, processes. This provides an important
            function to a programmer, the ability to change and modify part of an application
            without having to impact and rebuild the whole application.
        </p>
    </div>
    <div class="col-md-6 col-sm-12">
        <img src="/lab/static/images/guide/container-vm.png" class="img-responsive ">
    </div>
</div>
<p>
    Achieving this goal requires writing applications in such a way that they
    can communicate with each other through programmatic tools like RPC (remote
    procedure calls) or the newer term, API (application programing interface).
</p>
<p>
    In the past, people had different processes running on single servers. Then these
    evolved into running across networks through network RPCs. Complexity and lack
    of standards made these hard to manage. Then standard protocols where developed
    like ReST to be able to send data between network services. Different
    programmatic tooling to simplify creation of API's made it possible to now
    easily break applications into much smaller chunks.
</p>
<p>
    With that in mind, containers have evolved from the original LXC concepts
    to what they are today. A mechanism for developers to create services
    that are easy to deploy and manage, that can be orchestrated and managed
    in such a way that they are small, nimble and fast. Hence the term
    <strong>micro-services</strong> was coined.
</p>

<h1>
    Container orchestration
</h1>
<p>
    The process of orchestration of containers involved the development of tools that
    would make it possible to manage the lifecycle of the application through
    automation. These involves aspects like placement, scheduling, resource
    management, updates and monitoring.
</p>
<p>
    One of the key components of orchestration of containers is the declarative
    configuration model that is used throughout the eco-system. DEVOPS teams
    write the proper declarative configuration such that the automation uses this
    configuration throughout the architecture. This declarative configuration,
    usually accomplished with YAML or JSON contains all the crucial elements
    required by this application component to function. These might include
    network ports, storage, volumes and other parameters.
</p>
<p>
    It is also the job of the orchestrator to insure proper placement of
    workloads based on system activity, load and policy. For example,
    provisioning an application that has some sort of high availability
    requirement and placing all the components in the same physical compute
    node makes no sense.
</p>
<p>
    It is also the job of the orchestrator for monitoring health of the
    all the containers that compromise the application component and make sure
    that they are active and functional.
</p>
<p>
    There are many container orchestrators in the market. Three of the
    popular ones are: Kubernetes, Docker Swarm and Apache Mesos. Over the
    past years Kubernetes has been gaining traction in the industry as a
    leader in the orchestration space of containers and the reason why
    Cisco has developed this integration model, based on Cisco ACI user
    feedback.
</p>
<h1>
    Kubernetes
</h1>
<p>
    Kubernetes originated as an open source project in google loosely
    based on Google's own Borg architecture for managing their datacenter
    workloads ( Borg remains internal google only ). Kubernetes birth
    date is in the year 2014 and has been adopted and extended by the
    community since with many extensions added by other corporations and
    open-source advocates.
</p>
<p>
    From that birth in 2014 kubernetes continues to garner interest in the
    market. Different platforms utilize kubernetes as the basis for
    managing containers ( Rancher, OpenShift ). The internet can't
    stop asking questions about Kubernetes:
</p>
<img src="/lab/static/images/kubernetes-trends.png" class="img-responsive img-shadow">
<p>
    Which leads us as to why you are here with us today.
</p>
<h1>
    About this Lab!
</h1>
<img src="/core/static/images/landscapes/hero-bg-2.jpg" class="img-responsive">
<p>
    When we embarked on developing this lab we realized that understanding Cisco Container Platform and kubernetes
    without having some basis of containers didn't make sense. So we developed in the lab a
    structure that goes through showing some of the container basics.
</p>

<p>
    The lab from a high level has the following steps:
</p>
{{ html_for_step_status|safe }}
<p>
    We take the student through the following flow of learning:
</p>
<ul>
    <li>Deploying Cisco Container Platform on Cisco Hyperflex</li>
    <ul>
        <li>Overview of the platform, components, features etc.
        </li>
        <li>Deploying a Tenant integrated with ACI
        </li>
    </ul>
    <li>Deploying an Application on CCP</li>
    <ul>
        <li>Prometheus Agents</li>
        <li>Build Grafana Dashboards</li>
    </ul>
    <li>View Logging metrics in Kibana</li>
    <ul>
        <li>In this section, you will learn how to expose ingress for Kibana
        </li>
    </ul>
    <li>Building Security Policy in ACI for Kubernetes</li>
    <ul>
        <li>In this section of the lab, you will understand how to manage annotations and use them to build a micro segmented container platform
        </li>
    
    </ul>
    <li>Deploy Persistent Volume App</li>
    <ul>
        Here you will deploy an application and upgrade the version of it and examine the Persistent storage aspects of Cisco Hyperflex.
    </ul>
</ul>
<p>
    Any questions please reach out to the proctors. We are here to help and provide
    answers to any questions you may have. If we don't know, we will gladly find out
    a solution for you.
</p>





{{ end_of_page(page_position,data) }}
{% endblock %}
