{% extends "base_cisco.html" %}
{% from "macros.html" import file, warn, info, cmd_blk_end, cmd_blk_start, term_end, topxterm, term_start, end_of_page,top_instance, copythis %}
{% block content %}
{% set step =  0 %}
{% set innerstep =  0 %}


<div class="section_header">
    <div class="title">Cisco Livewall App</div>
    <div class="title_section">Deployment</div>
</div>
{{ html_for_step_status|safe }}

<h1>CCP Lab Toplogy</h1>
<p>In this section, you will be configuring an Application Proflie in ACI for a new application called 'Livewall' and then deploying
 the application to your CCP cluster.</p>
<img src="/lab/imgman/pod/{{ data.pod_id }}/id/991" class="img-responsive">


<!--
##############################################################################################################################
Step {% set step = step +  1 %}
##############################################################################################################################
-->
<h3>Step {{ step }} - Deploy "LiveWall" Application profile from CLI</h3>
<p>SSH using putty to your jumphost at IP address -{{data.pod_master_ip}}

</p>
<p>To save time, we will be using a script to quickly install the ACI App Profile. What we are doing in this step
  is to define and build the <code>network and security</code> configuration necessary for the application to run on ACI. This
step can also be performed manually by going into ACI and building the Application Profile, and creating the EPGs and the necessary
contracts. We are using API calls and a backend script to automate this process. In most production enviroments, people choose
various automation tools like ansible, puppet etc. or python and other programming language to interact with ACI's API.</p>
<div class="fancy-terminal">
<pre class="command-line language-bash" data-prompt="{{ data.master_prompt}}">
<code class="language-bash">
  cd $HOME/clemea20
  git pull
  ./lwAppProfile
</code>
</pre>
</div>
<br>

<!--
##############################################################################################################################
Step {% set step = step +  1 %}
##############################################################################################################################
-->
<h3>Step {{ step }} - Examine the changes in APIC</h3>
<p>
Click on Tenant and expand your pod to the Application Profiles section and then expand the new application profile called 'livewall' that we just deployed.
Take notice that we have deployed three new EPGs (collector, api, and frontend) and contracts between them. We have not yet
deployed the application, this is just the ACI configuration.
</p>
<img src="/lab/static/images/ccp/lwall2.png" class="img-responsive img-shadow">
<!--
##############################################################################################################################
Step {% set step = step +  1 %}
##############################################################################################################################
-->
<h3>Step {{ step }} - Are there any endpoints (devices?)</h3>
<p> If you click on one of the three EPGs and then click on 'Operational'
 tab, you will notice that there are no endpoints. Once we deploy the application,
 you will see new endpoints show up in the EPG.</p>
<img src="/lab/static/images/ccp/lwall22.png" class="img-responsive img-shadow">
<!--
##############################################################################################################################
Step {% set step = step +  1 %}
##############################################################################################################################
-->
<h3>Step {{ step }} - Log back to CCP to install CSI support Add-on</h3>
<p>
Go back to the tab/window with Cisco Container Platform <br>Log back in as '{{data.vmware_cred_username}}/C1sco123' if your session has expired,
otherwise click on 'Clusters' on the top left of navigation, locate your pod - {{data.vmware_cred_username}}</p>
<p>CSI or 'Container Storage Interface' was developed as a standard for exposing arbitrary block and file storage storage
  systems to containerized workloads on Container Orchestration Systems (COs) like Kubernetes. Using CSI, third-party
  storage providers like Cisco can write and deploy plugins exposing new storage systems in Kubernetes without ever
  having to touch the core Kubernetes code. This gives Kubernetes users more options for storage and makes the system
  more secure and reliable.</p>
<p>For {{data.vmware_cred_username}}, click on the icon below 'Actions' and click 'Add-ons' </p>
<img src="/lab/static/images/ccp/ccp9.png" class="img-responsive img-shadow">

<!--
##############################################################################################################################
Step {% set step = step +  1 %}
##############################################################################################################################
-->
<h3>Step {{ step }} - Click on 'INSTALL FIRST ADD-ON' and install 'HyperFlex Storage(CSI)'</h3>

<img src="/lab/static/images/ccp/ccp114.png" class="img-responsive img-shadow">
<img src="/lab/static/images/ccp/ccp24.png" class="img-responsive img-shadow">
<p>Click 'INSTALL' at the bottom right</p>
<p>This process might take a few minutes and the status from 'pending' to 'completed' takes a while;
  let's move on to the next step.</p>
<!--
##############################################################################################################################
Step {% set step = step +  1 %}
##############################################################################################################################
-->
<h3>Step {{ step }} - SSH to your jumpbox and deploy the containerized application</h3>
<p>SSH using putty to your jumphost at IP address -{{data.pod_master_ip}}
<br>Run the following commands from CLI to see the files necessary to install the application. (If you are
 familiar with linux navigation and text viewing tools like 'vi' & 'cat', feel free to explore the files in this folder)
  <div class="fancy-terminal">
  <pre class="command-line language-bash" data-prompt="{{ data.master_prompt}}">
  <code class="language-bash">
  cd $HOME/clemea20/01-livewall
  ls -lr
  </code>
  </pre>
  </div>

<br>Run the following commands from CLI; the shell script fires off a few kubernetes yaml manifests from the folder.
<div class="fancy-terminal">
<pre class="command-line language-bash" data-prompt="{{ data.master_prompt}}">
<code class="language-bash">
cd $HOME/clemea20/01-livewall
./01-launch-livewall.sh
</code>
</pre>
</div>
<!--
##############################################################################################################################
Step {% set step = step +  1 %}
##############################################################################################################################
-->
<h3>Step {{ step }} - Log back into ACI, open Operational tab under livewall app EPGs</h3>
<p><b>Notice anything different?</b><br>Now that we have deployed the actual application on kubernetes with the right annotations
for each pod to their respective EPG, you are able to see them in the operational tab. We use 'annotations', a kubernetes construct
designed to add identifiers based on a key/value pair as the mechanism to tell ACI which pods belong to which EPG. ACI is able
to provide microsegmentation based on PODs, Namespaces, Deployments and Clusters</p>
<img src="/lab/static/images/ccp/lwall4.png" class="img-responsive img-shadow">
<!--
##############################################################################################################################
Step {% set step = step +  1 %}
##############################################################################################################################
-->
<h3>Step {{ step }} - Examine the additions in the VMM domain section</h3>
<p>
Click on 'Virtual Networking' and Expand Kubernetes under 'Container Domains'</p>
<p>Expand {{data.vmware_cred_username}} and look for any pods in the 'default' namespace. An applicaiton can be deployed into the
default namespace or you can create a new namespace for it by defining it in the manifest. You can always move application tiers
to a different namespace at a later time.</p>
<img src="/lab/static/images/ccp/ccp203.png" class="img-responsive img-shadow">
<!--
##############################################################################################################################
Step {% set step = step +  1 %}
##############################################################################################################################
-->
<h3>Step {{ step }} - SSH back to your jumpbox to see the Deployment</h3>
<p>
  A deployment in kubernetes is essentially a mechanism
  to describe the 'desired state' of a pod or set of pods. For example, in an deployment you could mention that you need 3 replicas for
  an application tier. Kubernetes will honor that and make sure that there will be three copies of it running at all times.<br><br>
  From your jumphost, execute the following command to examine the deployments. </p>
<div class="fancy-terminal">
<pre class="command-line language-bash" data-prompt="{{ data.master_prompt}}">
<code class="language-bash">
kubectl get deployments
</code>
</pre>
</div>

      Notice that there are five deployments for this micro-service app <br>
  <img src="/lab/static/images/ccp/lwall5.png" class="img-responsive img-shadow">
<!--
##############################################################################################################################
Step {% set step = step +  1 %}
##############################################################################################################################
-->
<h3>Step {{ step }} - Find the 'frontend' IP address from kubernetes</h3>
<p>A 'service' is way to expose an application running on a set of Pods as a network service. Kubernetes Pods are mortal. They are born and when they die, they are not resurrected. If you use a Deployment to run your app, it can create and destroy Pods dynamically.

Each Pod gets its own IP address, however in a Deployment, the set of Pods running in one moment in time could be different from the set of Pods running that application a moment later.

This leads to a problem: if some set of Pods (call them “backends”) provides functionality to other Pods (call them “frontends”) inside your cluster, how do the frontends find out and keep track of which IP address to connect to, so that the frontend can use the backend part of the workload?

This is why services are important! Let's find out what services are available and exposed in our 'default' namespace. (if you don't define a namespace in kubectl, kubernetes assumes default)
</p>From your jumphost, execute
<div class="fancy-terminal">
<pre class="command-line language-bash" data-prompt="{{ data.master_prompt}}">
<code class="language-bash">
kubectl get svc
</code>
</pre>
</div>
  <img src="/lab/static/images/ccp/lwall6.png" class="img-responsive img-shadow"><br>
  <br>
  <!--
  ##############################################################################################################################
  Step {% set step = step +  1 %}
  ##############################################################################################################################
  -->
<h3>Step {{ step }} - Copy the EXTERNAL-IP address of the frontend LoadBalancer and open it in Chrome</h3>
<p>Please be patient as the server fetches data from various sites using API calls to build the frontend</p>
<img src="/lab/static/images/ccp/lwall7.png" class="img-responsive img-shadow">

{{ end_of_page(page_position,data) }}
{% endblock %}
